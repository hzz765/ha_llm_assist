{
  "config": {
    "step": {
      "user": {
        "data": {
          "model_type": "[%key:common::config_flow::data::model_type%]"
        }
      },
      "tongyi": {
        "data": {
          "api_key": "[%key:common::config_flow::data::api_key%]",
          "chat_model": "[%key:common::config_flow::data::chat_model%]"
        }
      },
      "openai": {
        "data": {
          "api_key": "[%key:common::config_flow::data::api_key%]",
          "chat_model": "[%key:common::config_flow::data::chat_model%]",
          "base_url": "[%key:common::config_flow::data::base_url%]"
        }
      },
      "qianfan": {
        "data": {
          "api_key": "[%key:common::config_flow::data::api_key%]",
          "chat_model": "[%key:common::config_flow::data::chat_model%]",
          "secret_key": "[%key:common::config_flow::data::secret_key%]"
        }
      },
      "common_config": {
        "data": {
          "name": "[%key:common::config_flow::data::name%]"
        }
      }
    },
    "error": {
      "cannot_connect": "[%key:common::config_flow::error::cannot_connect%]",
      "invalid_auth": "[%key:common::config_flow::error::invalid_auth%]",
      "unknown": "[%key:common::config_flow::error::unknown%]"
    }
  },
  "options": {
    "step": {
      "init": {
        "data": {
          "system_prompt": "System Prompt Template",
          "human_prompt": "Human Prompt Template",
          "top_p": "Top P",
          "temperature": "Temperature",
          "max_tokens": "Max Tokens",
          "langchain_max_iterations": "The maximum number of steps to take before ending the execution loop",
          "langchain_memory_window_size": "Number of messages to store in buffer"
        }
      }
    }
  },
  "selector": {
    "llm_model_class": {
      "options": {
        "Tongyi": "Tongyi",
        "OpenAI": "OpenAI",
        "Qianfan":"Qianfan"
      }
    }
  }
}
